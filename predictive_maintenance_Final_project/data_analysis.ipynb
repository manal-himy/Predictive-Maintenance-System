#%%
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from xgboost import XGBClassifier
from imblearn.over_sampling import SMOTE
#%%
# 1. تحميل البيانات من الملف الذي رفعته
df = pd.read_csv('data/predictive_maintenance.csv')
#%%
# 2. حذف المعرفات  لأنها تعيق التعلم
df.drop(['UDI', 'Product ID'], axis=1, inplace=True)
#%%
# عرض الحجم والتحقق من القيم المفقودة
print(f"Dataset Shape: {df.shape}")
print("Missing Values:\n", df.isnull().sum())

#%%
df['Target'].value_counts()
#%%
print(df.tail(10)) 
#%%


statistics = df.describe()

averages = df.mean(numeric_only=True)

# طباعة النتائج
print("--- الإحصائيات الوصفية للحساسات ---")
print(statistics)

print("\n--- المتوسط الحسابي لكل حساس ---")
print(averages)

#%%
# اختيار الهدف الجديد (نوع الفشل)
y = df['Failure Type'] 
X = df.drop(['Target', 'Failure Type'], axis=1)
#%%
# ترميز الهدف (Label Encoding) للأرقام من 0 إلى 5
le = LabelEncoder()
y_encoded = le.fit_transform(y)
num_classes = len(le.classes_)
#%%
# تقسيم البيانات لتدريب واختبار
X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42,stratify=y_encoded)
print("Classes found:", le.classes_)
#%%
# تحديد الأعمدة الرقمية والفئوية
numeric_features = ['Air temperature [K]', 'Process temperature [K]', 
                    'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']
categorical_features = ['Type']
#%%
# إنشاء المعالج
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numeric_features),
        ('cat', OneHotEncoder(), categorical_features)
    ])
#%%
# تحويل بيانات التدريب والاختبار (تمهيداً لـ SMOTE)
X_train_pre = preprocessor.fit_transform(X_train)
X_test_pre = preprocessor.transform(X_test)
#%%
# توليد بيانات اصطناعية للأعطال النادرة
print("Before SMOTE:", np.bincount(y_train))

smote = SMOTE(random_state=42)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train_pre, y_train)

print("After SMOTE:", np.bincount(y_train_resampled))
#%%
# تحويل البيانات المولدة إلى DataFrame لرؤيتها
df_smote = pd.DataFrame(X_train_resampled)
df_smote['Target_Encoded'] = y_train_resampled

# عرض أول 10 صفوف من الأعطال التي كانت نادرة وأصبحت كثيرة
print("عينة من البيانات بعد التوليد:")
print(df_smote.head(60)) 
#%%
# تعريف الموديلات (بدون موازنة داخلية لأننا استخدمنا SMOTE)
models = {
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "XGBoost": XGBClassifier(objective='multi:softmax', num_class=num_classes, random_state=42),
    "SVM": SVC(probability=True, random_state=42),
    "KNN": KNeighborsClassifier(n_neighbors=5)
}

results = {}

for name, model in models.items():
    # التدريب على البيانات المتوازنة
    model.fit(X_train_resampled, y_train_resampled)
    
    # التنبؤ على بيانات الاختبار الحقيقية
    y_pred = model.predict(X_test_pre)
    
    print(f"\n======= Performance Report: {name} =======")
    print(classification_report(y_test, y_pred, target_names=le.classes_, zero_division=0))
    results[name] = accuracy_score(y_test, y_pred)
#%%
# اختيار XGBoost وتدريبه داخل Pipeline لسهولة الاستخدام لاحقاً
final_xgb = XGBClassifier(objective='multi:softmax', num_class=num_classes, random_state=42)

# التدريب النهائي
final_xgb.fit(X_train_resampled, y_train_resampled)

# تجميع المعالج مع الموديل في ملف واحد
final_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', final_xgb)
])

# الحفظ
joblib.dump(final_pipeline, 'predictive_maintenance_xgboost_model.pkl')
joblib.dump(le, 'label_encoder.pkl')

print("\n✅ تم تدريب الموديل وحفظه بنجاح! جاهز للاستخدام في Flask.")
#%%
# رسم مصفوفة الارتباك لأفضل موديل
y_pred_final = final_pipeline.predict(X_test)
cm = confusion_matrix(y_test, y_pred_final)

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=le.classes_, yticklabels=le.classes_)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix - Final XGBoost Model')
plt.show()
#%%
